---
title: List of Deep Learning Papers
sidebar:
  nav: docs-research
aside:
  toc: true
key: 20250710_list_DL
tags: 
lang: ko
---
# ğŸ“„ ëŒ€í‘œ ë…¼ë¬¸ë“¤

### **1980s ~ 2000s: íƒœë™ê¸°**

&emsp;\[1980\] Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position â€“ Fukushima

&emsp;\[1986\] Learning representations by back-propagating errors â€“ Rumelhart, Hinton, Williams

&emsp;\[1988\] Gradient-Based Learning Applied to Document Recognition â€“ LeCun et al. (LeNet-5)


### <span style="color: brown">**2012 ~ 2014: ë”¥ëŸ¬ë‹ ëŒ€ì¤‘í™” (CNN ì¤‘ì‹¬)**</span>

&emsp;\[2012\] ImageNet Classification with Deep Convolutional Neural Networks â€“ Krizhevsky, Sutskever, Hinton (AlexNet)

&emsp;\[2014\] Very Deep Convolutional Networks for Large-Scale Image Recognition â€“ Simonyan, Zisserman (VGGNet)

&emsp;\[2014\] Going Deeper with Convolutions â€“ Szegedy et al. (GoogLeNet/Inception)

&emsp;\[2014\] Generative Adversarial Nets â€“ Goodfellow et al. (GAN)

&emsp;\[2014\] Neural Machine Translation by Jointly Learning to Align and Translate â€“ Bahdanau et al. (Attention in Seq2Seq)


### <span style="color: brown">**2015 ~ 2017: êµ¬ì¡° í˜ì‹ ê³¼ Transformer ë“±ì¥**</span>

&emsp;\[2015\] Deep Residual Learning for Image Recognition â€“ He et al. (ResNet)

&emsp;\[2015\] U-Net: Convolutional Networks for Biomedical Image Segmentation â€“ Ronneberger et al.

&emsp;\[2015\] Human-level control through deep reinforcement learning â€“ Mnih et al. (DQN)

&emsp;\[2017\] Attention Is All You Need â€“ Vaswani et al. (Transformer)


### <span style="color: brown">**2018 ~ 2020: LLMê³¼ ì‚¬ì „í•™ìŠµ í˜ì‹ **</span>

&emsp;\[2018\] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding â€“ Devlin et al.

&emsp;\[2018\] Improving Language Understanding by Generative Pre-training â€“ Radford et al. (GPT-1)

&emsp;\[2019\] Language Models are Unsupervised Multitask Learners â€“ Radford et al. (GPT-2, ë…¼ë¬¸í™” ì—†ì´ ë³´ê³ ì„œ í˜•ì‹)

&emsp;\[2019\] RoBERTa: A Robustly Optimized BERT Pretraining Approach â€“ Liu et al.

&emsp;\[2019] XLNet: Generalized Autoregressive Pretraining for Language Understanding â€“ Yang et al.

&emsp;\[2020\] T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer â€“ Raffel et al.


### <span style="color: brown">**2021 ~ 2022: Vision Transformer, ë©€í‹°ëª¨ë‹¬, ìƒì„±ëª¨ë¸ ì§„í™”**</span>

&emsp;\[2021\] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale â€“ Dosovitskiy et al. (ViT)

&emsp;\[2021\] Learning Transferable Visual Models From Natural Language Supervision â€“ Radford et al. (CLIP)

&emsp;\[2021\] Zero-Shot Text-to-Image Generation â€“ Ramesh et al. (DALLÂ·E)

&emsp;\[2022\] Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding â€“ Saharia et al. (Imagen, by Google)

&emsp;\[2022\] Flamingo: A Visual Language Model for Few-Shot Learning â€“ DeepMind


### <span style="color: brown">**2023 ~ 2024: ë©€í‹°ëª¨ë‹¬ ëŒ€í†µí•© + AGI ì „ì´ˆ**</span>

&emsp;\[2023\] GPT-4 Technical Report â€“ OpenAI

&emsp;\[2023\] Segment Anything â€“ Kirillov et al. (Meta)

&emsp;\[2023\] LLaMA: Open and Efficient Foundation Language Models â€“ Touvron et al. (Meta)

&emsp;\[2023\] LLaVA: Visual Instruction Tuning â€“ Liu et al.

&emsp;\[2024\] GPT-4o: Omni-modal AI by OpenAI â€“ OpenAI

&emsp;\[2024\] Gemini 1.5 Technical Report â€“ Google DeepMind



